---
title: "Practica_2"
author: "Jesús Martínez Leal"
date: "2023-11-02"
output:
  html_document: default
  pdf_document: default
---

```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# Configuración general de chunks
library(knitr)
options(width = 100)
knitr::opts_chunk$set(echo = T, message = T, error = F, warning = F, comment = NA, dpi = 100, tidy = T, cache.path = '.cache/', fig.path = './figure/', include = T)
```

Como es habitual, cargamos las librerías que necesitamos al inicio del documento.

```{r librerias, message = T, include = T, echo = T}
# Carga de librerías necesarias con pacman
library(pacman)
pacman::p_load(readr, stringr, tidyr, dplyr, readxl, ggplot2, forcats, MASS)
```

# Ejercicio 2. Un estudio sobre datos de neuronas

Las neuronas funcionan generando y propagando potenciales de acción, llamados "spikes". El intervalo de tiempo entre dos spikes adyacentes, o inter-spikes interval (ISI), se utiliza a menudo en la neurocicencia computacional. En el archivo *neuronspikes.txt* puedes encontrar algunas mediciones de ISI.

Carga los datos en R y completa los siguienes ejercicios:

```{r}
isidata <- read.table("./data/neuronspikes.txt", col.names = "isi")
```

## Ejercicio 2.1. 

Si asumimos que las observaciones de ISI son i.i.d. siguen una distribución exponencial con parámetro $\lambda$, calcule el estimador de máxima verosimilitud de $\lambda$.

Sea $X_1, ..., X_n \sim \exp({\lambda})$ ($\lambda$ > 0) donde sabemos que la PDF es $f(x|\lambda) = \lambda \exp(-\lambda x)$.


La verosimilitud por definición:

$$\mathcal{L}_n(\lambda) = \prod_{i = 1}^n f(X_i|\lambda) = \prod_{i = 1}^n \lambda \exp(-\lambda X_i)$$

Nos será más sencillo trabajar con la función log-verosoimiltud por las propiedades de la función exponencial:


$$ℓ_n(\lambda) = \ln{\mathcal{L_n(\lambda)}} = \sum_{i = 1}^n (\ln(\lambda) + (-\lambda X_i)) = n \ln(\lambda) - \lambda \sum_{i = 1}^n(X_i)$$
Procedemos a calcular el valor de $\lambda$ que permite maximizar esta función, requiriendo acudir al cálculo diferencial.

Igualamos la primera derivada a cero para hallar los puntos críticos:

$$\frac{dℓ_n}{d\lambda} = \frac{n}{\lambda} - \sum_{i = 1} ^n (X_i) = 0 $$
Obtenemos despejando para $\lambda$:

$$\lambda = \frac{n}{\sum_{i = 1}^n} = \frac{1}{\bar{X}}$$
Para verificar que es un máximo acudimos al criterio de la segunda derivada, que nos ofrece:

$$ \frac{d^2ℓ_n}{d\lambda^2} = - \frac{n}{\lambda ^2}, $$, de tal forma que se ve que es siempre negativo dada nuestra restricción en el parámetro $\lambda$ de ser positivo.

Podemos entonces asegurar que el estimador de máxima verosimilitud de nuestro parámetro es:

$$\hat{\lambda} = \frac{1}{\bar{X}} $$
Así pues, tendremos:

```{r}
lambda_hat <- 1 / mean(isidata$isi)
cat("El parámetro estimado es", lambda_hat, "\n")
```
```{r}
mllk <- function(rate, data) {
  -sum((dexp(data, rate = rate, log = TRUE)))
}

optimize(f = mllk, data = isidata$isi, interval = c(0, 10))

rate_num_est <- optimize(f = mllk, data = isidata$isi, interval = c(0, 10))$minimum

hist(isidata$isi, breaks = 10, probability = TRUE)
curve(dexp(x, rate_num_est), add = TRUE, col = "blue")
```

Con una función implementada en R directamente nos ahorraríamos esto:

```{r}
data <- isidata$isi  

# Ajuste de los datos a función que especifiquemos
fit <- fitdistr(data, "exponential")

# Obtener parámetros
estimated_rate <- fit$estimate

# Print the results
cat("El parámetro estimado es", estimated_rate, "\n")
```

## Ejercicio 2.2

Ahora, asumiendo que las observaciones de ISI son i.i.d. y siguen una distribución gamma con paráemtros $\alpha$ (*shape*) y $\beta$ (*rate*), encuentre los estimadores de máxima verosimiltud de los parámetros $\alpha$ y $\beta$.

[here](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwiQuY3QqaWCAxV0UKQEHfzsA3YQFnoECA0QAw&url=https%3A%2F%2Fzenodo.org%2Frecord%2F4019900%2Ffiles%2FMLE_Gamma.pdf&usg=AOvVaw0jf-TZxBuj4LJFZZCs0ofh&opi=89978449)

Sacaremos numéricamente estos estimadores utilizando una función implementada en R:

```{r}
mllk <- function(params, data) {
  shape <- params[1]
  rate <- params[2]
  -sum(dgamma(data, shape = shape, rate = rate, log = TRUE))
}

params <- optim(c(1, 1), f = mllk, data = isidata$isi, method = c("Nelder-Mead"))$par

hist(isidata$isi , breaks = 10, probability = TRUE)
curve(dgamma(x, shape = params[1], rate = params[2]), add = TRUE, col = "blue")

```

```{r}
data <- isidata$isi  

# Ajuste de los datos a función que especifiquemos

fit <- fitdistr(data, "gamma")

# Obtener parámetros
estimated_shape <- fit$estimate["shape"]
estimated_rate <- fit$estimate["rate"]

cat("El valor de shape estimado es:", estimated_shape)
cat("\nEl valor de rate estimado es:", estimated_rate)

hist(isidata$isi , breaks = 10, probability = TRUE)
curve(dgamma(x, shape = estimated_shape, rate = estimated_rate), add = TRUE, col = "blue")
```

## Ejercicio 2.3

Para la distribución gamma, conocemos las fórmulas de la media y la varianza, como sigue,

$$ \mathbb{E} (X) = \frac{\alpha}{\beta} $$

$$\mathbb{V} (X) = \frac{\alpha}{\beta^2}$$

Tratar de encontrar el estimador de momentos de $\alpha$ y $\beta$. El estimador de momentos puede utilizarse para encontrar la primera estimación y para inicializar el algoritmo iterativo de MLE.

Tenemos las dos primeras ecuaciones del método de los momentos, por lo que tenemos lo siguiente. Si introducimos la primera ecuación en la segunda:

$$ \beta = \frac{\mathbb{E (X)}}{\mathbb{V (X)}} $$
Esto en R sería:

```{r}
beta_est <- mean(isidata$isi) / var(isidata$isi)
beta_est
```

Para $\alpha$ solamente resta sustituir:

$$ \alpha = \beta \mathbb{E (X)} $$

```{r}
alpha_est <- beta_est * mean(isidata$isi)
alpha_est
```

```{r}
mllk <- function(params, data) {
  shape <- params[1]
  rate <- params[2]
  -sum(dgamma(data, shape = shape, rate = rate, log = TRUE))
}

params <- optim(c(alpha_est, beta_est), f = mllk, data = isidata$isi, method = c("Nelder-Mead"))$par

params

hist(isidata$isi , breaks = 10, probability = TRUE)
curve(dgamma(x, shape = params[1], rate = params[2]), add = TRUE, col = "blue")
```

Vemos cómo la estimación ofrecida por el método de máxima verosimilitud converge, al igual que cuando en el apartado 2.2 se introdujo manualmente el valor para el estimador inicial de los parámetros.

## Ejercicio 2.4

La distribución exponencial es un caso especial de la distribución gamma cuando el parámetro de forma es igual a 1. Verifica este hecho gráficamente en R.

Una búsqueda simple en Wikipedia de *Gamma distribution* nos permite conocer la PDF de esta, siendo:

$$ f(x) = \frac{\beta ^ \alpha}{\Gamma(\alpha)} x ^{\alpha - 1} * \exp(-\beta x) $$

Automáticamente, si particularizamos para el factor *shape* ($\alpha$) que sea igual a 1 obtenemos la expresión para la PDF de la distribución exponencial, ($\Gamma$ (1) = (1 - 1) ! = 0! = 1, $x ^ 0  = 1, x > 0$).

Para ver esto de manera gráfica hacemos:

```{r}
shape_gamma <- c(1.5, 1.2, 1)
rate_gamma <- c(1, 1, 1)
rate_exp <- 1
x <- seq(0, 10, by = 0.01)

df <- data.frame(x = x,
                 pdf_gamma = dgamma(x, shape_gamma[1], rate_gamma[1]),
                 pdf_gamma2 = dgamma(x, shape_gamma[2], rate_gamma[2]),
                 pdf_gamma3 = dgamma(x, shape_gamma[3], rate_gamma[3]),
                 pdf_exp = dexp(x, rate_exp))

ggplot(df, aes(x = x)) +
  geom_line(aes(y = pdf_gamma, color = "Gamma1"), size = 1.5) +
  geom_line(aes(y = pdf_gamma2, color = "Gamma2"), size = 1.5) +
  geom_line(aes(y = pdf_gamma3, color = "Gamma3"), size = 1.5) +
  geom_line(aes(y = pdf_exp, color = "Exponential"), size = 1.5) +
  labs(y = "Density", x = "x") +
  ggtitle("Probability Density Functions of Gamma and Exponential Distributions") +
  scale_color_manual(values = c("Gamma1" = "blue", "Gamma2" = "orange", "Gamma3" = "green", "Exponential" = "red")) +
  theme_minimal() +
  theme(legend.position = "right")
```
Puede apareciarse como Gamma3 parece desaparecer. Esto es debido a que se encuentra solapada con la curva exponencial roja. Esto es inmediato de comprobar si se grafica la curva resta para su dominio de definición.

```{r}
plot(x, df$pdf_exp - df$pdf_gamma3, xlim = c(0, 10), ylim = c(-0.1, 0.1), type = "l", xlab = "x", ylab = "Diferencia Gamma3 con Exponential", col = "green")
```


## Ejercicio 2.5

Dado que el modelo exponencial está anidado en el modelo gamma, podemos realizar la prueba de razón de verosimilitud (likelihood-ratio test) para seleccionar entre los dos modelos. Realiza la prueba de razón de verosimilitud en R y reporta el valor de p resultante.

$H_0$: el modelo $\mathcal{M}_1$ es suficiente para describir los datos.





# Ejercicio 4. Conjunto de datos de células cerebrales

Continuamos el estudio del conjunto de datos de células cerebrales del Instituto Allen. 

```{r}
path <- "./data/cell_types.csv"
cell <- read.csv(path, sep = ",", dec = ".", na.strings = "")
```

## Ejercicio 4.1

**Enunciado**.

Encuentra numéricamente las estimaciones MLE de los parámetros de la distribución log-normal para las observaciones de *ramp spike time* (en R está implementada la log-normal dlnorm).

**Resolución**.

De manera análoga a como se ha procedido en ejercicios anteriores estimamos estos parámetros con la siguiente algoritmia:

```{r}
mllk_lnorm <- function(params, data) {
  meanlog <- params[1]
  sdlog <- params[2]
  -sum(dlnorm(data, meanlog = meanlog, sdlog = sdlog, log = TRUE))
}
```

```{r}
ramp <- na.omit(cell$ef__peak_t_ramp) # quito los NA para que no haya problemas

paramsLognormal <- optim(c(6, 4), f = mllk_lnorm, data = ramp, method = c("Nelder-Mead"))$par
names(paramsLognormal) <- c("meanlog", "sdlog")
print(paramsLognormal)

hist(ramp, breaks = 10, probability = TRUE, ylim = c(0, 0.2))
curve(dlnorm(x, meanlog = params[1], sdlog = params[2]), add = TRUE, col = "blue")
legend("topright", legend = paste("meanlog =", round(params[1], 2), ", sdlog =", round(params[2], 2)), col = "blue", lty = 1)

```

## Ejercicio 4.2

**Enunciado**.

Como su nombre sugiere, la distribución log-normal está relacionada con la distribución Gaussiana. En particular, si $X$ es una distribución lognormal con parámetros μ y σ, entonces log(X) es una distribución normal con valor medio μ y desviación estándar σ. Ahora probaremos este hecho empíricamente. Transforma las observaciones de ”ramp spike time” utilizando el logaritmo y luego obtén la MLE de los parámetros para una distribución Gaussiana utilizando los datos transformados. Comprueba que los resultados que obtengas sean iguales a las estimaciones MLE obtenidas numéricamente en el punto 4.1.

**Resolución**

```{r}
mllk_norm <- function(params, data) {
  mean <- params[1]
  sd <- params[2]
  -sum(dnorm(data, mean = mean, sd = sd, log = TRUE))
}
```

```{r}
logramp <- log(ramp)

paramsNormal <- optim(c(6, 4), f = mllk_norm, data = logramp, method = c("Nelder-Mead"))$par
names(paramsNormal) <- c("mean", "sd")
print(paramsNormal)

# Se obtienen resultados prácticamente iguales? 
# Calculamos el error relativo

tol <- 1e-3

if(all(abs(paramsNormal - paramsLognormal) / paramsNormal < c(tol, tol)) == TRUE) {cat("Se ha probado empíricamente que los resultados obtenidos son iguales (o casi iguales por temas numéricos).")}
```

## Ejercicio 4.3

**Enunciado**

Encuentra ahora las estimaciones MLE de los parámetros de la distribución log-normal utilizando solo las observaciones de seres humanos masculinos y seres humanos femeninos. Grafica las dos densidades log-normal obtenidas en la misma gráfica.

**Resolución**

Filtramos primeramente haciendo uso de dplyr el dataframe para tener las observaciones de *males* y *females* por separado.

```{r}
cell_male <- cell %>%
  filter(donor__sex == "Male")

cell_female <- cell %>%
  filter(donor__sex == "Female")
```

Pasamos ahora a la resolución del ejercicio, análogamente a como se hizo en apartados anteriores.

```{r}
ramp_male <- na.omit(cell_male$ef__peak_t_ramp) 
ramp_female <- na.omit(cell_female$ef__peak_t_ramp)


paramsLognormal_male <- optim(c(6, 4), f = mllk_lnorm, data = ramp_male, method = c("Nelder-Mead"))$par
paramsLognormal_female <- optim(c(6, 4), f = mllk_lnorm, data = ramp_female, method = c("Nelder-Mead"))$par

parameter_matrix <- matrix(0, nrow = 2, ncol = 2)
parameter_matrix[1, ] <- paramsLognormal_male
parameter_matrix[2, ] <- paramsLognormal_female
rownames(parameter_matrix) <- c("Male", "Female")
colnames(parameter_matrix) <- c("meanlog", "sdlog")

kable(parameter_matrix)
```

Por último, graficamos:

```{r}
x <- seq(0, max(ramp_male), by = 0.01)

plot(x, dlnorm(x, meanlog = paramsLognormal_male[1], sdlog = paramsLognormal_male[2]), type = "l", col = "blue", lwd = 2, xlab = "x", ylab = "Density", xlim = c(0, max(ramp_male)), ylim = c(0, 0.15))
lines(x, dlnorm(x, meanlog = paramsLognormal_female[1], sdlog = paramsLognormal_female[2]), col = "red", lwd = 2)

legend("topright", legend = c("Male", "Female"), col = c("blue", "red"), lwd = 2)
title("Densidades Log-Normal para Male y Female")

```

