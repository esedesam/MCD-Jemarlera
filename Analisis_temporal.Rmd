---
title: \vspace{5cm} Análisis de una serie temporal. Tráfico comercial en el aeropuerto de Valencia.

author: ""
include-before:
- \usepackage[spanish]{babel}
- \usepackage[utf8]{inputenc}
- \usepackage{amsmath,amssymb,amsfonts}
- \usepackage{color}
- \usepackage{xcolor}
- \usepackage{graphicx}
- \usepackage{eqnarray}
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '1'
    citation_package: natbib
    number_sections: yes
    
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center", fig.width = 7, message = FALSE, warning = FALSE)
```

\newpage

En este caso práctico analizamos la serie temporal correspondiente a la generación de los distintos tipos de energía en Estados Unidos. Cargamos los cuatro paquetes de R que vamos a utilizar en el análisis e inicializamos el entorno.

```{r}
rm(list = ls())
library(readr)
library(forecast)
library(ggplot2)
library(dplyr)
setwd("D:/CDC-Jemarlera") # TENEIS QUE SETEAR EL WD
```

Seteamos algunas constantes útiles, en este caso, las etiquetas de los ejes de las representaciones gráficas van a ser constantes en la mayoría de gráficos.

```{r}
x_label <- "Tiempo / años"
y_label <- "Energía generada / MWh"
```

Para hacernos una idea de los datos que tenemos, lo mejor qu epodemo shacer es representarlos. Tras cargar el dataset, generamos una gráfica coon todos los tipos de energía.

```{r}
# Cargamos el csv con los datos generación de energía en US
Dat <- read.csv(file = "./data/organised_Gen.csv", header = TRUE, sep= ",", dec = ".")

# Eliminamos la columna de indices
Dat <- Dat %>%
  select(-X)

# Printeamos la información del DataFrame
# columns_to_check <- names(Dat)[1:(ncol(Dat) - 1)]
# for (column in columns_to_check) {
#   unique_values <- unique(Dat[[column]])
#   num_unique_values <- length(unique_values)
#   cat(column, ": ", unique_values, " || Total Values:", num_unique_values, "\n\n")
# }

# Construimos la columna date
Dat <- Dat %>%
  mutate(date = as.Date(paste(YEAR, MONTH, "01", sep = "-"), format = "%Y-%m-%d")) %>%
  select(date, everything()) %>%
  select(-YEAR, -MONTH) %>%
  rename(gen.MWh = GENERATION..Megawatthours.)

# Eliminamos datos mal formateados
Dat <- na.omit(Dat)

# Nos quedamos con el total de US
Total_gen <- filter(Dat, STATE == "US-TOTAL")

total_by_source <- Total_gen %>%
  group_by(date, ENERGY.SOURCE) %>%
  summarise(across(where(is.numeric), sum)) %>%
  ungroup()

ggplot(total_by_source[total_by_source$ENERGY.SOURCE != "Total",], aes(x = date, y = gen.MWh, color = ENERGY.SOURCE)) +
  geom_line() +
  scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
  theme_minimal() +
  labs(
    title = "Generación de energía por fuente de energía",
    x = x_label,
    y = y_label,
    color = "Type"
  )  +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "top", legend.box = "horizontal", legend.text = element_text(size = 5)) +
  guides(color = guide_legend(title = "Type"))
```

Ahora elegimos la fuente de energía a estudiar.

```{r}
sel_energia <- "Total" # Solar -> "Solar Thermal and Photovoltaic" QUITAR ESTO
switch(sel_energia,
       "Solar Thermal and Photovoltaic" = {
         energy_source_label <- "Energía solar-térmica y fotovoltaica"
       },
       "Wind" = {
         energy_source_label <- "Energía eólica"
       },
       "Total" = {
         energy_source_label <- "Energía total"
       },
       {
         energy_source_label <- sel_energia
       })

energy_source_df_all <- filter(total_by_source, ENERGY.SOURCE == sel_energia) %>%
  select(-ENERGY.SOURCE)

#Seleccionamos el periodo de tiempo a estudiar

start_idx <- which(energy_source_df_all$date == "2012-01-01")
end_idx <- which(energy_source_df_all$date == "2021-12-01")

energy_source_df <- energy_source_df_all[start_idx:end_idx,]
head(energy_source_df)

#Generamos la serie temporal

energy_source_ts <- ts(data = energy_source_df$gen.MWh, start = c(2012, 01), frequency = 12)
```

# Descripción gráfica de la serie temporal

Es habitual comenzar el análisis de una serie con la representación gráfica de los valores observados de la variable de interés en función del tiempo: 

```{r}
autoplot(energy_source_ts, xlab = "Tiempo / años", ylab = "Generación de energía / MWh") +
  ggtitle(energy_source_label) +
  theme_light()
```

A partir del gráfico temporal podemos apreciar una cierta evolución en el largo plazo (*tendencia*): durante los primeros cuatro años se observa una tendencia decreciente. A partir de 2014, la serie temporal toma valores cada vez mayores, es decir, la serie presenta una tendencia creciente. Por otro lado, se observa un comportamiento cíclico que se repite año tras año (*estacionalidad*), con una mayor generación de eenrgía durante los meses de verano. La longitud del ciclo estacional es $c = 12$. 

En este ejemplo, la estacionalidad de la serie se observa claramente en el gráfico temporal. No obstante, el diagrama de cajas por mes nos permite también valorar la presencia de estacionalidad.

```{r}
energy_source_df <- energy_source_df %>%
  mutate(mes = format(date, "%B"))

energy_source_df$mes <- factor(energy_source_df$mes,
                       levels = c("enero", "febrero", "marzo", "abril", "mayo", "junio",
                                  "julio", "agosto", "septiembre", "octubre", "noviembre", "diciembre"))

# Ordenamos los meses para que los represente por orden temporal

boxplot(energy_source_df$gen.MWh ~ energy_source_df$mes, xlab = "Tiempo / años", ylab = "Generación de energía / MWh", main = energy_source_label)
```

Una gráfica estacional es similar a una gráfica temporal, excepto que los datos se dibujan contra las “estaciones” individuales en las que se observaron los datos. A continuación se ofrece un ejemplo:
```{r}
ggseasonplot(energy_source_ts, year.labels = TRUE, year.labels.left = TRUE) +
  ylab("Generación de energía / MWh") +
  ggtitle(paste("Seasonal plot:", energy_source_label)) + 
  theme_light()
```


# Análisis de la serie mediante suavizado exponencial

Dadas las características de la serie temporal: tendencia y estacionalidad, el método adecuado para su análisis es el método de Holt-Winters.

Vamos a empezar analizando la serie con el método de Holt-Winters aditivo pues, a partir del gráfico temporal, podríamos asumir que el efecto de la estacionalidad es multiplicativo (parece aumentar con el nivel). No obstante, analizaremos también la serie con el método de Holt-Winters aditivo y la serie transformada (utilizando la transformación logarítmica) con Holt-Winters aditivo. 

Utilizamos los datos hasta diciembre de 2021 para el ajuste y reservamos las observaciones de 2022 para valorar la capacidad predictiva del método seleccionado. La predicción para el año 2022 la realizaremos utilizando el método que nos proporciones un mejor ajuste.

## Holt-Winters aditivo

```{r}
insample <- window(energy_source_ts, start = c(2012,1), end = c(2020,12))
outsample <- window(energy_source_ts, start = c(2021,1), end = c(2021,12))

energy_source_HW_add <- HoltWinters(insample, seasonal="additive")
energy_source_HW_add$coefficients
energy_source_HW_add$alpha
energy_source_HW_add$beta
energy_source_HW_add$gamma

fitval_add <- fitted(energy_source_HW_add)  
# fitval contiene la serie de valores ajustados en la primera columna (fitval_add[,1] = xhat)

plot(energy_source_HW_add, xlab = x_label, ylab = y_label,
     main = paste("Ajuste HW aditivo:", energy_source_label))

# Valoramos la bondad del ajuste
insamplecut <- window(insample, start = c(2013,1), end = c(2020,12))
# El año 2012 se utiliza para calcular las condiciones iniciales. 
# El ajuste pues se obtiene a partir de enero de 2013.

rmse_add <- sqrt(mean( (insamplecut - fitval_add[,1]) ^ 2 ))
mape_add <- 100 * mean( abs(insamplecut - fitval_add[,1]) / insamplecut )
rmse_add; mape_add
```

## Holt-Winters multiplicativo

```{r}
energy_source_HW_mult <- HoltWinters(insample, seasonal = "multiplicative")
energy_source_HW_mult$coefficients
energy_source_HW_mult$alpha
energy_source_HW_mult$beta
energy_source_HW_mult$gamma

fitval_mult <- fitted(energy_source_HW_mult)  

plot(energy_source_HW_mult, xlab = x_label, ylab = y_label,
     main = paste("Ajuste HW multiplicativo:", energy_source_label))

# Valoramos la bondad del ajuste
rmse_mult <- sqrt(mean( (insamplecut - fitval_mult[,1]) ^ 2 ))
mape_mult <- 100*mean( abs(insamplecut - fitval_mult[,1]) / insamplecut )
rmse_mult; mape_mult
```

## Holt-Winters aditivo aplicado a la serie transformada

```{r}
loginsample <- log(insample) 

energy_source_HW_log_add <- HoltWinters(loginsample, seasonal = "additive")
energy_source_HW_log_add$coefficients
energy_source_HW_log_add$alpha
energy_source_HW_log_add$beta
energy_source_HW_log_add$gamma

fitval_log <- fitted(energy_source_HW_log_add)  

plot(energy_source_HW_log_add, xlab = x_label, ylab = y_label,
     main = paste("Ajuste HW aditivo a serie logarítmica:", energy_source_label))

# Valoramos la bondad del ajuste. Para ello, volvemos previamente a la escala original

fitval_ori <- exp(fitval_log[,1])

rmse_log <- sqrt(mean( (insamplecut - fitval_ori) ^ 2 ))
mape_log <- 100*mean( abs(insamplecut - fitval_ori) / insamplecut )
rmse_log; mape_log
```

El método con menor error de ajuste (tanto RMSE como MAPE) es Holt-Winters con estacionalidad multiplicativa. Este será, por tanto, el método utilizado para calcular la predicción para el año 2022. 

```{r}
# Elegimos el HW a usar
energy_source_HW <- energy_source_HW_mult
```

```{r}
pred <- predict(energy_source_HW, 12)
# Valoramos la capacidad predictiva del método
rmse_pred <- sqrt(mean( (outsample - pred) ^ 2 ))
mape_pred <- 100 * mean( abs(outsample - pred) / outsample )
rmse_pred; mape_pred

# pred contiene las predicciones puntuales para los 12 meses de 2021
ts.plot(insample, pred, lty = 1:2,
        gpars = list(xlab = x_label, ylab = y_label,
                     main = paste("Predicción para el año 2022:", energy_source_label)))
legend("topleft", legend = c("Datos 2012-2020", "Predicción 2022"),
       lty = c(1, 2))
```
Podemos también representar gráficamente los valores reales de 2022 que habíamos reservado junto con la predicción puntual:

```{r}
plot(pred, col = "red", xaxt = "n", xlab = "Año 2022", ylab = y_label,
     main = paste("Datos y predicción del año 2022:", energy_source_label))
points(outsample, pch = 19)
legend("topleft", legend = c("Predicción Holt Winters", "Datos reales"),
       col = c("red", "black"), pch = c(NA, 19), lty = c(1, 0))
```

y calcular el intervalo de predicción al 95\%:

```{r}
pred <- predict(energy_source_HW, n.ahead = 12, prediction.interval = TRUE, level = 0.95) 
plot(energy_source_HW, pred, xlab = x_label, ylab = y_label,
     main = paste("Intervalo de predicción al 95% para el año 2022:", energy_source_label))
legend("topleft", legend = c("Datos 2012-2020", "Predicción completa", "Confianza 95%"),
       col = c("black", "red", "blue"), lty = 1)
```

# Análisis de la serie mediante la metodología Box-Jenkins

Dadas las características de la serie temporal: tendencia y estacionalidad, el primer paso del análisis es determinar la transformación estacionaria de la serie.

Calculamos un diferencia estacional ($D = 1$):

```{r}
d12insample <- diff(insample, 12)
plot(d12insample)
```

Parece que hemos quitado la estacionalidad, pero todavía queda la tendencia. Calculamos pues una diferencia regular ($d = 1$):

```{r}
dd12insample <- diff(d12insample)
plot(dd12insample)
```

Podemos asumir que la serie diferenciada con $d = 1$ y $D = 1$ ya es estacionaria. Pasamos a examinar el correlograma y el correlograma parcial:

```{r}
acf(dd12insample,lag.max=50)
pacf(dd12insample,lag.max=50)
```

Si nos fijamos en los primeros retardos, podemos pensar:

* La función de autocorrelación tiene el primer coeficiente significativo, mientras que la función de autocorrelación parcial muestra decrecimiento: (p,d,q) = (0,1,1)

* La función de autocorrelación decrece y la función de autocorrelación parcial tiene el primer coeficiente significativo: (p,d,q) = (1,1,0)

* Las dos funciones muestran decrecimiento a partir del primer coeficiente: (p,d,q) = (1,1,1)

Si nos fijamos en los retardos estacionales (Lag = 1, 2, 3, 4 ciclos estacionales), podemos pensar:

* No hay ningún coeficiente significativo: (P,D,Q) = (0,1,0)

* La función de autocorrelación tiene el primer coeficiente significativo, mientras que la función de autocorrelación parcial muestra decrecimiento: (P,D,Q) = (0,1,1)

Veamos el ajuste proporcionado por los distintos modelos:

```{r}
Pasajeros_model1 <- arima(insample, order=c(0,1,1), seasonal=list(order=c(0,1,0), period=12))
Pasajeros_model1

Pasajeros_model2 <- arima(insample, order=c(0,1,1), seasonal=list(order=c(0,1,1), period=12))
Pasajeros_model2

Pasajeros_model3 <- arima(insample, order=c(1,1,0), seasonal=list(order=c(0,1,0), period=12))
Pasajeros_model3

Pasajeros_model4 <- arima(insample, order=c(1,1,0), seasonal=list(order=c(0,1,1), period=12))
Pasajeros_model4

Pasajeros_model5 <- arima(insample, order=c(1,1,1), seasonal=list(order=c(0,1,0), period=12))
Pasajeros_model5

Pasajeros_model6 <- arima(insample, order=c(1,1,1), seasonal=list(order=c(0,1,1), period=12))
Pasajeros_model6


Pasajeros_model <- auto.arima(insample)
Pasajeros_model

accuracy(Pasajeros_model)
```

El modelo de menor AIC es (p,d,q)(P,D,Q) = (0,1,1)(0,1,1), que coincide con el modelo proporcionado por la función <code>auto.arima</code>. El MAPE asociado a este modelo es 2.4599. La ecuación del modelo es: 
$$
\bigtriangledown \bigtriangledown_{12} x_t = (1 - 0.3712 B) (1 - 0.2461 B^{12})\epsilon_t
$$
$$
(1 - B) (1 - B^{12}) x_t = (1 - 0.3712 B) (1 - 0.2461 B^{12})\epsilon_t
$$

Veamos a continuación la representación gráfica del ajuste obtenido. Línea negra: valores reales, línea roja: valores ajustados. 

```{r}
fitval <- Pasajeros_model$fitted # Valores ajustados

plot(insample,ylab="Num Pasajeros")
lines(fitval,col="red")
```

Antes de pasar a la predicción, comprobamos que el modelo es válido. Como muestran las siguientes salidas, los residuos del modelo pueden considerarse ruido blanco. 

```{r}
checkresiduals(Pasajeros_model,plot=TRUE)
```

La predicción obtenida para los 12 meses de 2019 junto con el error de predicción vienen dados por:

```{r}
pred <- forecast(Pasajeros_model,h=12)$mean
pred # Predicción puntual

plot(forecast(Pasajeros_model,h=12))

rmse_pred <- sqrt(mean((outsample-pred)^2))
mape_pred <- 100*mean(abs(outsample-pred)/outsample)
rmse_pred;mape_pred
```

Finalmente, representamos gráficamente los valores reales de 2019 que habíamos reservado junto con la predicción puntual:

```{r}
plot(pred, col="red",xaxt="n",xlab="Año 2019")
points(outsample,pch=19)
```

Si comparamos ambas metodologías, vemos que el error de ajuste correspondiente al modelo sARIMA es menor que el obtenido con Holt-Winters aditivo y, por tanto, como predicción para el año 2019 deberíamos haber tomado las obtenidas con la metodología Box-Jenkins. Además, como habíamos reservado las observaciones  de 2019 para valorar la capacidad predictiva del modelo, comprobamos que las predicciones obtenidas con el modelo sARIMA son, también, más precisas (menor error de predicción).  