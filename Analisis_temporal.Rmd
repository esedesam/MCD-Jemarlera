---
title: "Análisis de una serie temporal"
author: "Jesús Martínez Leal, Samuel Ortega Mediavilla & Pablo Vicente Martínez"
subtitle: US Energy Generation
output:
  html_document:
    df_print: paged
    toc: yes
    citation_package: natbib
    number_sections: yes
  pdf_document:
    toc: yes
include-before:
- \usepackage[spanish]{babel}
- \usepackage[utf8]{inputenc}
- \usepackage{amsmath,amssymb,amsfonts}
- \usepackage{color}
- \usepackage{xcolor}
- \usepackage{graphicx}
- \usepackage{eqnarray}
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center", fig.width = 7, message = FALSE, warning = FALSE)
```

\newpage

En este caso práctico analizamos la serie temporal correspondiente a la generación de los distintos tipos de energía en Estados Unidos. Cargamos los paquetes de R que vamos a utilizar en el análisis e inicializamos el entorno.

```{r}
rm(list = ls()) # borrado de variables previas
library(readr)
library(forecast)
library(ggplot2)
library(dplyr)
library(astsa)
library(knitr)
#setwd("D:/CDC-Jemarlera") # TENEIS QUE SETEAR EL WD
```

Seteamos algunas constantes útiles, en este caso, las etiquetas de los ejes de las representaciones gráficas van a ser constantes en la mayoría de gráficos.

```{r}
x_label <- "Tiempo / años"
y_label <- "Energía generada / MWh"
y_label_log <- " log(Energía generada / MWh)"
```

Para hacernos una idea de los datos que tenemos, lo mejor que podemos hacer es representarlos. Tras cargar el dataset, generamos una gráfica coon todos los tipos de energía.

```{r}
# Cargamos el csv con los datos generación de energía en US
Dat <- read.csv(file = "./data/organised_Gen.csv", header = TRUE, sep = ",", dec = ".")

# Eliminamos la columna de indices
Dat <- Dat %>%
  select(-X)

# Construimos la columna date
Dat <- Dat %>%
  mutate(date = as.Date(paste(YEAR, MONTH, "01", sep = "-"), format = "%Y-%m-%d")) %>%
  select(date, everything()) %>%
  select(-YEAR, -MONTH) %>%
  rename(gen.MWh = GENERATION..Megawatthours.)

# Eliminamos datos mal formateados
Dat <- na.omit(Dat)

# Nos quedamos con el total de US
Total_gen <- filter(Dat, STATE == "US-TOTAL")

# Calculamos el total por cada fuente de energía
total_by_source <- Total_gen %>%
  group_by(date, ENERGY.SOURCE) %>%
  summarise(across(where(is.numeric), sum)) %>%
  ungroup()

ggplot(total_by_source, aes(x = date, y = gen.MWh, color = ENERGY.SOURCE)) +
  geom_line() +
  scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
  theme_minimal() +
  labs(
    title = "Generación de energía por fuente de energía",
    x = x_label,
    y = y_label,
    color = "Type"
  )  +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "top", legend.box = "horizontal", legend.text = element_text(size = 5)) +
  guides(color = guide_legend(title = "Type"))
```

Ahora elegimos la fuente de energía a estudiar.

# Energía total

```{r}
sel_energia <- "Total"
switch(sel_energia,
       "Solar Thermal and Photovoltaic" = {
         energy_source_label <- "Energía solar-térmica y fotovoltaica"
       },
       "Wind" = {
         energy_source_label <- "Energía eólica"
       },
       "Total" = {
         energy_source_label <- "Energía total"
       },
       {
         energy_source_label <- sel_energia
       })

energy_source_df_all <- filter(total_by_source, ENERGY.SOURCE == sel_energia) %>%
  select(-ENERGY.SOURCE)

#Seleccionamos el periodo de tiempo a estudiar

start_idx <- which(energy_source_df_all$date == "2012-01-01")
end_idx <- which(energy_source_df_all$date == "2021-12-01")

energy_source_df <- energy_source_df_all[start_idx:end_idx,]
head(energy_source_df)

#Generamos la serie temporal

energy_source_ts <- ts(data = energy_source_df$gen.MWh, start = c(2012, 01), frequency = 12)
```

## Descripción gráfica de la serie temporal

Es habitual comenzar el análisis de una serie con la representación gráfica de los valores observados de la variable de interés en función del tiempo: 

```{r}
autoplot(energy_source_ts, xlab = "Tiempo / años", ylab = "Generación de energía / MWh") +
  ggtitle(energy_source_label) +
  theme_light()
```

A partir del gráfico temporal podemos apreciar carencia de *tendencia*: la energía total no presenta ni una evolución al alza o a la baja a lo largo del tiempo. Por otro lado, se observa un comportamiento cíclico que se repite año tras año (*estacionalidad*), con una mayor generación de energía durante los meses de verano. La longitud del ciclo estacional es $c = 12$. 

En este ejemplo, la estacionalidad de la serie se observa claramente en el gráfico temporal. No obstante, el diagrama de cajas por mes nos permite también valorar la presencia de estacionalidad.

```{r}
energy_source_df <- energy_source_df %>%
  mutate(mes = format(date, "%B"))

energy_source_df$mes <- factor(energy_source_df$mes,
                       levels = c("enero", "febrero", "marzo", "abril", "mayo", "junio",
                                  "julio", "agosto", "septiembre", "octubre", "noviembre", "diciembre"))

# Ordenamos los meses para que los represente por orden temporal

boxplot(energy_source_df$gen.MWh ~ energy_source_df$mes, xlab = "Mes", ylab = "Generación de energía / MWh", main = energy_source_label)
```

Una gráfica estacional es similar a una gráfica temporal, excepto que los datos se dibujan contra las “estaciones” individuales en las que se observaron los datos. A continuación se ofrece un ejemplo:

```{r}
ggseasonplot(energy_source_ts, year.labels = TRUE, year.labels.left = TRUE) +
  xlab("Mes")+
  ylab("Generación de energía / MWh") +
  ggtitle(paste("Seasonal plot:", energy_source_label)) + 
  theme_light()
```


## Análisis de la serie mediante suavizado exponencial

Dadas las características de la serie temporal (solo presenta estacionalidad) el método adecuado para su análisis es el de Holt-Winters (ya que este podría tratar una posible tendencia difícil de observar a simple vista, sirviendo de generalización.)

Compararemos los resultados obtenidos a partir del método Holt-Winters aditivo, Holt-Winters multiplicativo, así como del Holt-Winters aditivo pero aplicado a la serie transformada (con logaritmo).


Utilizamos los datos hasta diciembre de 2020 para el ajuste y reservamos las observaciones de 2021 para valorar la capacidad predictiva del método seleccionado. La predicción para el año 2021 la realizaremos utilizando el método que nos proporcione un mejor ajuste.

### Holt-Winters aditivo

Este método aditivo agrega el factor de estacionalidad a la previsión con tendencia, tal y como se vio en clase.

```{r}
insample <- window(energy_source_ts, start = c(2012,1), end = c(2020,12))
outsample <- window(energy_source_ts, start = c(2021,1), end = c(2021,12))

energy_source_HW_add <- HoltWinters(insample, seasonal="additive")
energy_source_HW_add$coefficients
energy_source_HW_add$alpha
energy_source_HW_add$beta
energy_source_HW_add$gamma

fitval_add <- fitted(energy_source_HW_add)  
# fitval contiene la serie de valores ajustados en la primera columna (fitval_add[,1] = xhat)

plot(energy_source_HW_add, xlab = x_label, ylab = y_label,
     main = paste("Ajuste HW aditivo:\n", energy_source_label))

# Valoramos la bondad del ajuste
insamplecut <- window(insample, start = c(2013,1), end = c(2020,12))
# El año 2012 se utiliza para calcular las condiciones iniciales. 
# El ajuste pues se obtiene a partir de enero de 2013.

rmse_add <- sqrt(mean( (insamplecut - fitval_add[,1]) ^ 2 ))
mape_add <- 100 * mean( abs(insamplecut - fitval_add[,1]) / insamplecut )
```

### Holt-Winters multiplicativo

En este caso el factor de estacionalidad aparece multiplicando a la previsión con tendencia: de ahí el nombre del método.

```{r}
energy_source_HW_mult <- HoltWinters(insample, seasonal = "multiplicative")
energy_source_HW_mult$coefficients
energy_source_HW_mult$alpha
energy_source_HW_mult$beta
energy_source_HW_mult$gamma

fitval_mult <- fitted(energy_source_HW_mult)  

plot(energy_source_HW_mult, xlab = x_label, ylab = y_label,
     main = paste("Ajuste HW multiplicativo:\n", energy_source_label))

# Valoramos la bondad del ajuste
rmse_mult <- sqrt(mean( (insamplecut - fitval_mult[,1]) ^ 2 ))
mape_mult <- 100*mean( abs(insamplecut - fitval_mult[,1]) / insamplecut )
```

### Holt-Winters aditivo aplicado a la serie transformada

Una alternativa al método multiplicativo consiste en realizar previamente una transformación logarítmica a los datos. La serie logarítmica se analiza con el método de Holt-Winters aditivo. A las predicciones obtenidas se les aplica una transformación exponencial para regresar a las unidades originales.

```{r}
loginsample <- log(insample) 

energy_source_HW_log_add <- HoltWinters(loginsample, seasonal = "additive")
energy_source_HW_log_add$coefficients
energy_source_HW_log_add$alpha
energy_source_HW_log_add$beta
energy_source_HW_log_add$gamma

fitval_log <- fitted(energy_source_HW_log_add)  

plot(energy_source_HW_log_add, xlab = x_label, ylab = y_label,
     main = paste("Ajuste HW aditivo a serie logarítmica:\n", energy_source_label))

# Valoramos la bondad del ajuste. Para ello, volvemos previamente a la escala original

fitval_ori <- exp(fitval_log[,1])

rmse_log <- sqrt(mean( (insamplecut - fitval_ori) ^ 2 ))
mape_log <- 100*mean( abs(insamplecut - fitval_ori) / insamplecut )
```
### Construcción de la Tabla de resultados obtenidos con los distintos métodos

```{r}
error_ajuste <- matrix(c(rmse_add, mape_add, rmse_mult, mape_mult, rmse_log, mape_log), nrow = 3, byrow = TRUE)
rownames(error_ajuste) <- c("Aditivo", "Multiplicativo", "Log-Aditivo")
colnames(error_ajuste) <- c("RMSE / $", "MAPE / %")
kable(error_ajuste, caption = "Tabla 1. Resultados obtenidos con los distintos métodos de suavizado", align = "c")
```



Como podemos observar, el RMSE es más pequeño en el caso multiplicativo, pero el MAPE es ligeramente menor en el caso logarítmico aditivo. Dado que la serie temporal admitimos que carece de heterocedasticidad, el método que usaremos para realizar la predicción del año 2021 será el Holt-Winters con estacionalidad **multiplicativa**.

### Selección del mejor método para realizar la predicción

El método escogido es el Holt-Winters multiplicativo por lo que se comentó anteriormente.

```{r}
# Elegimos el HW a usar
energy_source_HW <- energy_source_HW_mult

pred <- predict(energy_source_HW, 12)

# Valoramos la capacidad predictiva del método
rmse_pred <- sqrt(mean( (outsample - pred) ^ 2 ))
mape_pred <- 100 * mean( abs(outsample - pred) / outsample )

cat("Predicción para 2021:\nRMSE:", rmse_pred, "$", "\nMAPE:", mape_pred, "%", "\n")

# pred contiene las predicciones puntuales para los 12 meses de 2022
ts.plot(insample, pred, lty = 1:2,
        gpars = list(xlab = x_label, ylab = y_label,
                     main = paste("Predicción para el año 2021:\n", energy_source_label)))
legend("topleft", legend = c("Datos 2012-2020", "Predicción 2021"),
       lty = c(1, 2))
```

Podemos también representar gráficamente los valores reales de 2022 que habíamos reservado junto con la predicción puntual:

```{r}
plot(pred, col = "red", xaxt = "n", xlab = "Año 2021", ylab = y_label,
     main = paste("Datos y predicción del año 2021:\n", energy_source_label))
points(outsample, pch = 19)
legend("topleft", legend = c("Predicción Holt Winters", "Datos reales"),
       col = c("red", "black"), pch = c(NA, 19), lty = c(1, 0))
```
Podemos observar cómo nuestra predicción queda muy cerca de todos los datos reales, dando por satisfactorio nuestro resultado obtenido.

Así mismo, es posible determinar el intervalo de predicción al 95\% en nuestro modelo, tal y como se muestra en la siguiente Figura.

```{r}
pred <- predict(energy_source_HW, n.ahead = 12, prediction.interval = TRUE, level = 0.95) 
plot(energy_source_HW, pred, xlab = x_label, ylab = y_label,
     main = paste("Intervalo de predicción al 95% para el año 2021:\n", energy_source_label))
legend("topleft", legend = c("Datos 2012-2021", "Predicción completa", "Confianza 95%"),
       col = c("black", "red", "blue"), lty = 1)
```

## Análisis de la serie mediante la metodología Box-Jenkins

Con la metodología Box-Jenkins la idea es describir el valor observado en un período *t* como una función lineal de valores anteriores y errores debidos al azar.

### Transformación estacionaria de la serie

El primer paso en esta metodología es determinar la transformación estacionaria de la serie.

En primera instancia, calculamos una diferencia estacional ($D = 1$):

```{r}
d12insample <- diff(insample, 12)
plot(d12insample, xlab = x_label, ylab = y_label,
     main = paste("Serie diferenciada con D = 1:\n", energy_source_label))
```

Parece que hemos quitado la estacionalidad. A simple vista, como ya hemos comentado, parece que no existe tendencia en nuestra serie, pero para asegurar un correcto análisis de los datos diferenciaremos una segunda vez. En caso de que esta segunda diferenciación no fuese necesaria se haría evidente a la hora de utilizar los modelos predictivos. 

Calculamos pues una diferencia regular ($d = 1$):

```{r}
dd12insample <- diff(d12insample)
plot(dd12insample, xlab = x_label, ylab = y_label,
     main = paste("Serie diferenciada con D = 1 y d = 1:\n", energy_source_label))
```

Podemos asumir que la serie diferenciada con $d = 1$ y $D = 1$ ya es estacionaria. 

### Identificación de un modelo basado en análisis de autocorrelaciones y autocorrelaciones parciales

Pasamos a examinar el correlograma y el correlograma parcial:

```{r}
acf_result <- acf(dd12insample,lag.max = 50, plot = FALSE)

plot(acf_result)
custom_xticks <- seq(0, 5, by = 0.5)
axis(1, at = custom_xticks, labels = custom_xticks)

pacf_result <- pacf(dd12insample,lag.max = 50, plot = FALSE)
plot(pacf_result)
custom_xticks <- seq(0, 5, by = 0.5)
axis(1, at = custom_xticks, labels = custom_xticks)
```
Si nos fijamos en los primeros retardos, podemos pensar:

* La función de autocorrelación tiene dos coeficiente significativos, al igual que la función de autocorrelación parcial: (p,d,q) = (2,1,2)

* La función de autocorrelación decrece desde el primer máximo y la función de autocorrelación parcial tiene los dos primeros coeficientes significativos: (p,d,q) = (1,1,2)

* Interpretamos de la misma forma las funciones que en el anterior punto pero no diferenciamos la serie: (p,d,q) = (1,0,2)

* Utilizamos la función <code>auto.arima</code> para comparar nuestros modelos, diseñados observando las funciones de autocorrelación, con el que se supone que optimiza la predicción.

Por otra parte, si nos fijamos en los retardos estacionales (Lag = 1, 2, 3, 4 ciclos estacionales), podemos pensar:

* La función de autocorrelación muestra decrecimiento, mientras que la función de autocorrelación parcial podemos considerar que tiene el primer coeficiente significativo: (P,D,Q) = (0,1,1)

* La función de autocorrelación muestra decrecimiento, mientras que la de autocorrelación parcial tiene los dos primeros coeficientes significativos: (P,D,Q) = (0,1,2)

Veamos el ajuste proporcionado por los distintos modelos:

**Modelo 1.**

```{r}
source_energy_model_1 <- arima(insample, order = c(2,1,2), seasonal = list(order=c(0,1,2), period=12))
source_energy_model_1

#Modelo 1: p values

source_energy_model_1s <- sarima(dd12insample,2,1,2,0,1,2,12, details = FALSE)
source_energy_model_1s$ttable
```

**Modelo 2.**

```{r}
source_energy_model_2 <- arima(insample, order = c(1,1,2), seasonal = list(order = c(0,1,1), period=12))
source_energy_model_2

#Modelo 2: p values
source_energy_model_2s <- sarima(dd12insample,1,1,2,0,1,1,12, details = FALSE)
source_energy_model_2s$ttable
```

**Modelo 3.**

```{r}
source_energy_model_3 <- arima(insample, order = c(1,0,2), seasonal = list(order = c(0,1,1), period = 12))
source_energy_model_3

#Modelo 3: p values
source_energy_model_3s <- sarima(dd12insample,1,0,2,0,1,1,12, details = FALSE)
source_energy_model_3s$ttable
```

**Modelo predicho por Auto-Arima.**

```{r}
source_energy_model_auto <- auto.arima(insample)
source_energy_model_auto
```

El modelo de menor AIC (con p-values aceptables menores a 0.05) es (p,d,q)(P,D,Q) = (1,1,2)(0,1,1), que no coincide con el modelo proporcionado por la función <code>auto.arima</code>. 

Los estadísticos relacionados con el modelo 2 son:

```{r, echo = FALSE}
accuracy(source_energy_model_2)
```

La ecuación del modelo 2 queda como: 

$$
(1- 0.5579B)(1-0.5579B^{12})(1 - B) (1 - B^{12}) x_t = (1 -1.1140B + 0.1140B^{2}) (1 -  B^{12})\epsilon_t
$$

Veamos a continuación la representación gráfica del ajuste obtenido. Línea negra: valores reales, línea roja: valores ajustados. 

```{r}
# Elegimos modelo
source_energy_model <- source_energy_model_2
fitval <- fitted(source_energy_model)

plot(insample, xlab = x_label, ylab = y_label,
     main = paste("Ajuste de ARIMA:\n", energy_source_label))
lines(fitval, col = "red")
```

Antes de pasar a la predicción, comprobamos que el modelo es válido. Como muestran las siguientes salidas, los residuos del modelo pueden considerarse ruido blanco. 

```{r}
checkresiduals(source_energy_model, plot=TRUE)
```

La predicción obtenida para los 12 meses de 2021 junto con el error de predicción vienen dados por:

```{r}
pred <- forecast(source_energy_model, h = 12)$mean
pred # Predicción puntual

plot(forecast(source_energy_model,h=12), xlab = x_label, ylab = y_label,
     main = paste("Intervalos de confianza de ARIMA para 2022:\n", energy_source_label))

rmse_pred <- sqrt(mean((outsample-pred)^2))
mape_pred <- 100*mean(abs(outsample-pred)/outsample)

cat("Predicción para 2022:\nRMSE:", rmse_pred, "\nMAPE:", mape_pred, "\n")
```

Finalmente, representamos gráficamente los valores reales de 2022 que habíamos reservado junto con la predicción puntual:

```{r}
plot(pred, col="red",xaxt="n", xlab = "Año 2021", ylab = y_label,
     main = paste("Datos y predicción sARIMA para el año 2021:\n", energy_source_label))
points(outsample,pch=19)
legend("topleft", legend = c("Predicción sARIMA", "Datos reales"),
       col = c("red", "black"), pch = c(NA, 19), lty = c(1, 0))
```

En la siguiente Tabla se recogen los errores RMSE y MAPE de suavizado exponencial con Holt-Winters y con el modelo de sARIMA.

```{r}
tabla_comparacion <- matrix(c(16904653, 1.959043, 15817957, 1.8845), nrow = 2, byrow = TRUE)
rownames(tabla_comparacion) <- c("Holt-Winters (multiplicativo)", "sARIMA")
colnames(tabla_comparacion) <- c("RMSE / $", "MAPE / %")
kable(tabla_comparacion, caption = "Tabla 2. Comparación entre modelo de Holt-Winters y de sARIMA", align = "c")
```

Si comparamos ambas metodologías, vemos que el error de ajuste correspondiente al modelo sARIMA es menor que el obtenido con Holt-Winters multiplicativo y, por tanto, como predicción para el año 2021 deberíamos haber tomado las obtenidas con la metodología Box-Jenkins. Además, como habíamos reservado las observaciones  de 2021 para valorar la capacidad predictiva del modelo, comprobamos que las predicciones obtenidas con el modelo sARIMA son, también, más precisas (menor error de predicción).

# Solar

Repetimos para la energía solar, que tiene tendencia y heterocedasticidad, además de estacionalidad.

```{r}
sel_energia <- "Solar Thermal and Photovoltaic"
switch(sel_energia,
       "Solar Thermal and Photovoltaic" = {
         energy_source_label <- "Energía solar-térmica y fotovoltaica"
       },
       "Wind" = {
         energy_source_label <- "Energía eólica"
       },
       "Total" = {
         energy_source_label <- "Energía total"
       },
       {
         energy_source_label <- sel_energia
       })

energy_source_df_all <- filter(total_by_source, ENERGY.SOURCE == sel_energia) %>%
  select(-ENERGY.SOURCE)

#Seleccionamos el periodo de tiempo a estudiar

start_idx <- which(energy_source_df_all$date == "2012-01-01")
end_idx <- which(energy_source_df_all$date == "2021-12-01")

energy_source_df <- energy_source_df_all[start_idx:end_idx,]
head(energy_source_df)

#Generamos la serie temporal

energy_source_ts <- ts(data = energy_source_df$gen.MWh, start = c(2012, 01), frequency = 12)
```

## Descripción gráfica de la serie temporal

Es habitual comenzar el análisis de una serie con la representación gráfica de los valores observados de la variable de interés en función del tiempo: 

```{r}
autoplot(energy_source_ts, xlab = "Tiempo / años", ylab = "Generación de energía / MWh") +
  ggtitle(energy_source_label) +
  theme_light()
```

A partir del gráfico temporal podemos apreciar una cierta evolución en el largo plazo (*tendencia*): durante todos los años se observa una tendencia creciente. A partir de 2017, la serie temporal toma crece de forma proporcionalmente más lenta, pero se mantiene la tendencia. Además, podemos identificar un aumento en la variabilidad de los datos a lo largo del tiempo (*heterocedasticidad*). Por otro lado, se observa un comportamiento cíclico que se repite año tras año (*estacionalidad*), con una mayor generación de energía durante los meses de verano. La longitud del ciclo estacional es $c = 12$. 

En este ejemplo, la estacionalidad de la serie se observa claramente en el gráfico temporal. No obstante, el diagrama de cajas por mes nos permite también valorar la presencia de estacionalidad.

```{r}
energy_source_df <- energy_source_df %>%
  mutate(mes = format(date, "%B"))

energy_source_df$mes <- factor(energy_source_df$mes,
                       levels = c("enero", "febrero", "marzo", "abril", "mayo", "junio",
                                  "julio", "agosto", "septiembre", "octubre", "noviembre", "diciembre"))

# Ordenamos los meses para que los represente por orden temporal

boxplot(energy_source_df$gen.MWh ~ energy_source_df$mes, xlab = "Tiempo / años", ylab = "Generación de energía / MWh", main = energy_source_label)
```

Una gráfica estacional es similar a una gráfica temporal, excepto que los datos se dibujan contra las “estaciones” individuales en las que se observaron los datos. A continuación se ofrece un ejemplo:

```{r}
ggseasonplot(energy_source_ts, year.labels = TRUE, year.labels.left = TRUE) +
  xlab("Mes") +
  ylab("Generación de energía / MWh") +
  ggtitle(paste("Seasonal plot:", energy_source_label)) + 
  theme_light()
```


## Análisis de la serie mediante suavizado exponencial

Dadas las características de la serie temporal: tendencia, estacionalidad y heterocedasticidad; el método adecuado para su análisis es el método de Holt-Winters.

Compararemos los resultados obtenidos a partir del método Holt-Winters aditivo, Holt-Winters multiplicativo, así como del Holt-Winters aditivo pero aplicado a la serie transformada (con logaritmo).

Utilizamos los datos hasta diciembre de 2020 para el ajuste y reservamos las observaciones de 2021 para valorar la capacidad predictiva del método seleccionado. La predicción para el año 2021 la realizaremos utilizando el método que nos proporciones un mejor ajuste.

### Holt-Winters aditivo

Este método aditivo agrega el factor de estacionalidad a la previsión con tendencia, tal y como se vio en clase.

```{r}
insample <- window(energy_source_ts, start = c(2012,1), end = c(2020,12))
outsample <- window(energy_source_ts, start = c(2021,1), end = c(2021,12))

energy_source_HW_add <- HoltWinters(insample, seasonal="additive")
energy_source_HW_add$coefficients
energy_source_HW_add$alpha
energy_source_HW_add$beta
energy_source_HW_add$gamma

fitval_add <- fitted(energy_source_HW_add)  
# fitval contiene la serie de valores ajustados en la primera columna (fitval_add[,1] = xhat)

plot(energy_source_HW_add, xlab = x_label, ylab = y_label,
     main = paste("Ajuste HW aditivo:\n", energy_source_label))

# Valoramos la bondad del ajuste
insamplecut <- window(insample, start = c(2013,1), end = c(2020,12))
# El año 2012 se utiliza para calcular las condiciones iniciales. 
# El ajuste pues se obtiene a partir de enero de 2013.

rmse_add <- sqrt(mean( (insamplecut - fitval_add[,1]) ^ 2 ))
mape_add <- 100 * mean( abs(insamplecut - fitval_add[,1]) / insamplecut )
```

### Holt-Winters multiplicativo

En este caso el factor de estacionalidad aparece multiplicando a la previsión con tendencia: de ahí el nombre del método.

```{r}
energy_source_HW_mult <- HoltWinters(insample, seasonal = "multiplicative")
energy_source_HW_mult$coefficients
energy_source_HW_mult$alpha
energy_source_HW_mult$beta
energy_source_HW_mult$gamma

fitval_mult <- fitted(energy_source_HW_mult)  

plot(energy_source_HW_mult, xlab = x_label, ylab = y_label,
     main = paste("Ajuste HW multiplicativo:\n", energy_source_label))

# Valoramos la bondad del ajuste
rmse_mult <- sqrt(mean( (insamplecut - fitval_mult[,1]) ^ 2 ))
mape_mult <- 100*mean( abs(insamplecut - fitval_mult[,1]) / insamplecut )
```

### Holt-Winters aditivo aplicado a la serie transformada

Una alternativa al método multiplicativo consiste en realizar previamente una transformación logarítmica a los datos. La serie logarítmica se analiza con el método de Holt-Winters aditivo. A las predicciones obtenidas se les aplica una transformación exponencial para regresar a las unidades originales.

```{r}
loginsample <- log(insample) 

energy_source_HW_log_add <- HoltWinters(loginsample, seasonal = "additive")
energy_source_HW_log_add$coefficients
energy_source_HW_log_add$alpha
energy_source_HW_log_add$beta
energy_source_HW_log_add$gamma

fitval_log <- fitted(energy_source_HW_log_add)  

plot(energy_source_HW_log_add, xlab = x_label, ylab = y_label_log,
     main = paste("Ajuste HW aditivo a serie logarítmica:\n", energy_source_label))

# Valoramos la bondad del ajuste. Para ello, volvemos previamente a la escala original

fitval_ori <- exp(fitval_log[,1])

rmse_log <- sqrt(mean( (insamplecut - fitval_ori) ^ 2 ))
mape_log <- 100*mean( abs(insamplecut - fitval_ori) / insamplecut )
```
### Construcción de la Tabla de resultados obtenidos con los distintos métodos

```{r}
error_ajuste <- matrix(c(rmse_add, mape_add, rmse_mult, mape_mult, rmse_log, mape_log), nrow = 3, byrow = TRUE)
rownames(error_ajuste) <- c("Aditivo", "Multiplicativo", "Log-Aditivo")
colnames(error_ajuste) <- c("RMSE / $", "MAPE / %")
kable(error_ajuste, caption = "Tabla 3. Resultados obtenidos con los distintos métodos de suavizado", align = "c")
```

El método con menor error de ajuste (tanto RMSE como MAPE) es Holt-Winters con estacionalidad multiplicativa. Este será, por tanto, el método utilizado para calcular la predicción para el año 2021. 

### Selección del mejor método para realizar la predicción

El método escogido es el Holt-Winters multiplicativo por lo que se comentó anteriormente.

```{r}
# Elegimos el HW a usar
energy_source_HW <- energy_source_HW_mult

pred <- predict(energy_source_HW, 12)
# Valoramos la capacidad predictiva del método
rmse_pred <- sqrt(mean( (outsample - pred) ^ 2 ))
mape_pred <- 100 * mean( abs(outsample - pred) / outsample )

cat("Predicción para 2021:\nRMSE:", rmse_pred, "\nMAPE:", mape_pred, "\n")

# pred contiene las predicciones puntuales para los 12 meses de 2021
ts.plot(insample, pred, lty = 1:2,
        gpars = list(xlab = x_label, ylab = y_label,
                     main = paste("Predicción para el año 2021:\n", energy_source_label)))
legend("topleft", legend = c("Datos 2012-2020", "Predicción 2021"),
       lty = c(1, 2))
```

Podemos también representar gráficamente los valores reales de 2022 que habíamos reservado junto con la predicción puntual:

```{r}
plot(pred, col = "red", xaxt = "n", xlab = "Año 2021", ylab = y_label,
     main = paste("Datos y predicción del año 2021:\n", energy_source_label))
points(outsample, pch = 19)
legend("topleft", legend = c("Predicción Holt Winters", "Datos reales"),
       col = c("red", "black"), pch = c(NA, 19), lty = c(1, 0))
```
De nuevo, al igual que en el caso de la energía total, los puntos reales no distan demasiado a simple vista de lo que ofrece nuestra predicción Holt-Winters.

Así mismo, es posible determinar el intervalo de predicción al 95\% en nuestro modelo, como se muestra en la siguiente Figura.

```{r}
pred <- predict(energy_source_HW, n.ahead = 12, prediction.interval = TRUE, level = 0.95) 
plot(energy_source_HW, pred, xlab = x_label, ylab = y_label,
     main = paste("Intervalo de predicción al 95% para el año 2021:\n", energy_source_label))
legend("topleft", legend = c("Datos 2012-2020", "Predicción completa", "Confianza 95%"),
       col = c("black", "red", "blue"), lty = 1)
```

## Análisis de la serie mediante la metodología Box-Jenkins

Con la metodología Box-Jenkins la idea es describir el valor observado en un período t como una función lineal de valores anteriores y errores debidos al azar.

### Transformación estacionaria de la serie

Con objetivo de quitar la heterocedasticidad aplicamos la función logaritmo primeramente.

```{r}
loginsample <- log(insample)
plot(loginsample, xlab = x_label, ylab = y_label_log,
     main = paste("Serie logarítmica:\n", energy_source_label))
```

Hemos conseguido eliminar la heterocedasticidad a la vista de lo obtenido.

Ahora,se procede a calcular una diferencia estacional ($D = 1$):

```{r}
d12insample <- diff(loginsample, 12)
plot(d12insample, xlab = x_label, ylab = y_label_log,
     main = paste("Serie logarítmica diferenciada con D = 1:\n", energy_source_label))
```

Diferenciando no parece que hayamos conseguido eliminar la estacionalidad plenamente. 

Probamos ahora la diferencia regular ($d = 1$):

```{r}
dd12insample <- diff(d12insample)
plot(dd12insample, xlab = x_label, ylab = y_label_log,
     main = paste("Serie logarítmica diferenciada con D = 1 y d = 1:\n", energy_source_label))
```

Podemos asumir que la serie logarítmica diferenciada con $d = 1$ y $D = 1$ ya es estacionaria para proseguir con nuestro análisis más detallado. 

### Identificación de un modelo basado en análisis de autocorrelaciones y autocorrelaciones parciales

Pasamos a examinar el correlograma y el correlograma parcial:

```{r}
acf_result <- acf(dd12insample,lag.max = 50, plot = FALSE)

plot(acf_result)
custom_xticks <- seq(0, 5, by = 0.5)
axis(1, at = custom_xticks, labels = custom_xticks)

pacf_result <- pacf(dd12insample,lag.max = 50, plot = FALSE)
plot(pacf_result)
custom_xticks <- seq(0, 5, by = 0.5)
axis(1, at = custom_xticks, labels = custom_xticks)
```

Si nos fijamos en los primeros retardos, podemos pensar:

* Tanto la función de autocorrelación como la función de autocorrelación parcial tienen el primer coeficiente significativo: (p,d,q) = (0,1,0)

* Las dos funciones muestran decrecimiento a partir del primer coeficiente: (p,d,q) = (1,1,1)

Si nos fijamos en los retardos estacionales (Lag = 1, 2, 3, 4 ciclos estacionales), podemos pensar:

* La función de autocorrelación parcial tiene el primer coeficiente significativo, mientras que la función de autocorrelación muestra decrecimiento: (P,D,Q) = (0,1,1)

Veamos el ajuste proporcionado por los distintos modelos:

**Modelo 1.**

```{r}
source_energy_model_1 <- arima(loginsample, order = c(0,1,0), seasonal = list(order=c(0,1,1), period=12))
source_energy_model_1
#Modelo 1: p values
source_energy_model_1s <- sarima(loginsample,0,1,0,0,1,1,12, details = FALSE)
source_energy_model_1s$ttable
```

**Modelo 2.**
```{r}
source_energy_model_2 <- arima(loginsample, order = c(1,1,1), seasonal = list(order = c(0,1,1), period=12))
source_energy_model_2
#Modelo 2: p values
source_energy_model_2s <- sarima(loginsample,1,1,1,0,1,1,12, details = FALSE)
source_energy_model_2s$ttable
```

**Modelo predicho por Auto-Arima**

```{r}
source_energy_model_auto <- auto.arima(loginsample)
source_energy_model_auto
```

El modelo de menor AIC es (p,d,q)(P,D,Q) = (0,1,0)(0,1,1), que coincide con el modelo proporcionado por la función <code>auto.arima</code>. Los estadísticos asociados a este modelo son:

```{r, echo = FALSE}
accuracy(source_energy_model_1)
```

La ecuación del modelo es: 

$$
\bigtriangledown x_t = (1 - 0.693 B)\epsilon_t
$$
$$
(1 - B) x_t = (1 - 0.693 B)\epsilon_t
$$

Veamos a continuación la representación gráfica del ajuste obtenido. Línea negra: valores reales, línea roja: valores ajustados. 

```{r}
# Elegimos modelo
source_energy_model <- source_energy_model_1
fitval <- fitted(source_energy_model)

plot(loginsample, xlab = x_label, ylab = y_label_log,
     main = paste("Ajuste de ARIMA:\n", energy_source_label))
lines(fitval, col = "red")
```

Antes de pasar a la predicción, comprobamos que el modelo es válido. Como muestran las siguientes salidas, los residuos del modelo pueden considerarse ruido blanco. 

```{r}
checkresiduals(source_energy_model, plot=TRUE)
```

La predicción obtenida para los 12 meses de 2021 junto con el error de predicción vienen dados por:

```{r}
logoutsample <- log(outsample)

pred <- forecast(source_energy_model, h = 12)$mean
pred # Predicción puntual

plot(forecast(source_energy_model,h=12), xlab = x_label, ylab = y_label_log,
     main = paste("Intervalos de confianza de ARIMA para 2021:\n", energy_source_label))

rmse_pred <- sqrt(mean((logoutsample-pred)^2))
mape_pred <- 100*mean(abs(logoutsample-pred)/logoutsample)

cat("Predicción para 2021:\nRMSE:", rmse_pred, "\nMAPE:", mape_pred, "\n")
```

Finalmente, representamos gráficamente los valores reales de 2021 que habíamos reservado junto con la predicción puntual:

```{r}
plot(pred, col="red",xaxt="n", xlab = "Año 2021", ylab = y_label_log,
     main = paste("Datos y predicción ARIMA para el año 2021 (logaritmo):\n", energy_source_label))
points(logoutsample,pch=19)
legend("topleft", legend = c("Predicción ARIMA", "Datos reales"),
       col = c("red", "black"), pch = c(NA, 19), lty = c(1, 0))
```

Podemos recuperar la serie original y la predicción correspondiente deshaciendo la conversión logarítmica:

```{r}
plot(exp(pred), col="red",xaxt="n", xlab = "Año 2021", ylab = y_label,
     main = paste("Datos y predicción ARIMA para el año 2021:\n", energy_source_label))
points(outsample,pch=19)
legend("topleft", legend = c("Predicción ARIMA", "Datos reales"),
       col = c("red", "black"), pch = c(NA, 19), lty = c(1, 0))
```
```{r}
# Cálculo de RMSE y MAPE para la serie original

rmse_pred <- sqrt(mean((outsample-exp(pred)^2)))
mape_pred <- 100*mean(abs(outsample-exp(pred))/outsample)


```

En la siguiente Tabla se recogen el MAPE de suavizado exponencial con Holt-Winters y con el modelo de sARIMA:

```{r}
tabla_comparacion <- matrix(c(6.170981, 5.915143), nrow = 2, byrow = TRUE)
rownames(tabla_comparacion) <- c("Holt-Winters (multiplicativo)", "sARIMA")
colnames(tabla_comparacion) <- c( "MAPE / %")
kable(tabla_comparacion, caption = "Tabla 4. Comparación entre modelo de Holt-Winters y de sARIMA", align = "c")
```

Si comparamos ambas metodologías, vemos que el error de ajuste correspondiente al modelo sARIMA es menor que el obtenido con Holt-Winters aditivo y, por tanto, como predicción para el año 2021 deberíamos haber tomado las obtenidas con la metodología Box-Jenkins. Además, como habíamos reservado las observaciones  de 2021 para valorar la capacidad predictiva del modelo, comprobamos que las predicciones obtenidas con el modelo sARIMA son, también, más precisas (menor error de predicción).

